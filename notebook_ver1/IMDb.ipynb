{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb\n",
    "**Here we explore how to inject confounding bias into binary classification problems. **\n",
    "\n",
    "\n",
    "To do so, we consider a standard binary classification problem with feature matrix $X$ and labels $y$. We modify the training sample to inject a confounding bias.\n",
    "- Select a feature $f$ that has low chi2 value and occurs at least $N$ times but no more than $M$ times.\n",
    "- Sample a training set $D$ in which $f$ and $y$ have a specified correlation\n",
    "- Plot test accuracy as correlation varies.\n",
    "\n",
    "The experiments below use IMDB sentiment classification, where genre is presumed to be a confounder.\n",
    "\n",
    "We also look for examples of Simpson's Paradox. E.g., a coefficient as negative value when fit on all data, but has positive value in each genre.\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Dataset][1]\n",
    "  1. [Download data from Dropbox][2]\n",
    "  2. [Load data from files][3]\n",
    "2. [Experiments][4]\n",
    "  1. [Load models][5]\n",
    "  2. [Experiment helper functions][6]\n",
    "  3. [Correlation stats][7]\n",
    "  4. [Confounding experiments][8]\n",
    "  5. [Export plots][9]\n",
    "  6. [Simpson's paradox][10]\n",
    "  7. [Study effect of C value on accuracy][11]\n",
    "  8. [Change in model coefficients][12]\n",
    "  9. [Top terms table][13]\n",
    "[1]: #Dataset\n",
    "[2]: #Download-data-from-Dropbox\n",
    "[3]: #Load-data-from-files\n",
    "[4]: #Experiments\n",
    "[5]: #Load-models\n",
    "[6]: #Experiment-helper-functions\n",
    "[7]: #Correlation-stats\n",
    "[8]: #Confounding-experiments\n",
    "[9]: #Export-plots\n",
    "[10]: #Simpson's-paradox\n",
    "[11]: #Study-effect-of-C-value-on-accuracy\n",
    "[12]: #Change-in-model-coefficients\n",
    "[13]: #Top-terms-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "from scipy.stats import pearsonr, sem\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run confound_plot.py\n",
    "%run imdb_confounding_experiments.py\n",
    "%matplotlib inline\n",
    "%run injecting_bias.py\n",
    "%run models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Dropbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is [stored on Dropbox](https://www.dropbox.com/sh/pcg731664f8h4fy/AADu0H7h0-hh94TNNO43co9Ea/imdb-genres.tgz?dl=1) and its access is protected by a password. If you are interested in using the data for research purposes, please email one of the author to obtain the password. Once you have downloaded and unpacked the data, set the following `DATAPATH` variable to the path where the data is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = '/Users/ustctll/Desktop/dataset'\n",
    "IMDB = os.path.join(DATAPATH, 'aclImdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: x_train 25000 y_train 25000 c_train 25000\n",
      "train y distr Counter({1: 12500, 0: 12500}) c distr Counter({0: 20720, 1: 4280})\n",
      "train y and c distr Counter({'y=1,c=0': 11280, 'y=0,c=0': 9440, 'y=0,c=1': 3060, 'y=1,c=1': 1220})\n",
      "lengths: x_test 25000 y_test 25000 c_test 25000\n",
      "test y distr Counter({1: 12500, 0: 12500}) c distr Counter({0: 20363, 1: 4637})\n",
      "test y and c distr Counter({'y=1,c=0': 11063, 'y=0,c=0': 9300, 'y=0,c=1': 3200, 'y=1,c=1': 1437})\n",
      "vectorizing training data...\n"
     ]
    }
   ],
   "source": [
    "def read_files(path):\n",
    "    return [f for f in sorted(glob.glob(path), key=lambda x: int(x[x.rindex('/') + 1:x.index('_')]))]\n",
    "\n",
    "\n",
    "def read_genres(filename, label='Horror'):\n",
    "    \"\"\" Read genres, making a binary label. \"\"\"\n",
    "    genres = []\n",
    "    for line in open(filename):\n",
    "        if label in line:\n",
    "            genres.append(1)\n",
    "        else:\n",
    "            genres.append(0)            \n",
    "    return genres\n",
    "\n",
    "class Data(object):\n",
    "    pass\n",
    "\n",
    "def read_imdb_text(path):\n",
    "    x_train = read_files(path + '/train/pos/*.txt')\n",
    "    y_train = [1] * len(x_train)\n",
    "    c_train = read_genres(path + '/train/urls_pos.txt.genres')\n",
    "    x_train.extend(read_files(path + '/train/neg/*.txt'))\n",
    "    y_train.extend([0] * (len(x_train) - len(y_train)))    \n",
    "    c_train.extend(read_genres(path + '/train/urls_neg.txt.genres'))\n",
    "    print('lengths: x_train %d y_train %d c_train %d' % (len(x_train), len(y_train), len(c_train)))\n",
    "    print('train y distr', Counter(y_train), 'c distr', Counter(c_train))\n",
    "    print('train y and c distr', Counter(['y=%d,c=%d' % (y,c) for (y,c) in zip(y_train,c_train)]))\n",
    "    \n",
    "    x_test = read_files(path + '/test/pos/*.txt')\n",
    "    y_test = [1] * len(x_test)\n",
    "    c_test = read_genres(path + '/test/urls_pos.txt.genres')                                                              \n",
    "    x_test.extend(read_files(path + '/test/neg/*.txt'))\n",
    "    y_test.extend([0] * (len(x_test) - len(y_test)))\n",
    "    c_test.extend(read_genres(path + '/test/urls_neg.txt.genres'))\n",
    "    print('lengths: x_test %d y_test %d c_test %d' % (len(x_test), len(y_test), len(c_test)))\n",
    "    print('test y distr', Counter(y_test), 'c distr', Counter(c_test))\n",
    "    print('test y and c distr', Counter(['y=%d,c=%d' % (y,c) for (y,c) in zip(y_test,c_test)]))\n",
    "    \n",
    "    vectorizer = CountVectorizer(binary=True, min_df=10, stop_words='english')\n",
    "    print('vectorizing training data...')\n",
    "    X_train = vectorizer.fit_transform(open(f).read() for f in x_train)\n",
    "    print('shape=', X_train.shape)\n",
    "    print('vectorizing testing data...')\n",
    "    X_test = vectorizer.transform(open(f).read() for f in x_test)\n",
    "    print('shape=', X_test.shape)\n",
    "\n",
    "    data = Data()\n",
    "    print(type(X_train))\n",
    "    data.train_x = np.where(X_train.toarray()>0,1,0)\n",
    "    data.train_y = np.array(y_train)\n",
    "    data.train_c = np.array(c_train)\n",
    "    data.test_x = np.where(X_test.toarray()>0,1,0)\n",
    "    data.test_y = np.array(y_test)\n",
    "    data.test_c = np.array(c_test)\n",
    "    #data.vectorizer = vectorizer\n",
    "    data.feature_names = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    clf = lr(data.train_x, data.train_y, None, None, None)\n",
    "    pred_proba = clf.predict_proba(data.test_x)\n",
    "    data.test_d = np.array([1 - y_prob[y_true] for y_prob, y_true in zip(pred_proba, data.test_y)])\n",
    "    print('test instances difficulty: mean=%f, std=%f' % (np.mean(data.test_d), np.std(data.test_d)))\n",
    "    \n",
    "    clf = lr(data.test_x, data.test_y, None, None, None)\n",
    "    pred_proba = clf.predict_proba(data.train_x)\n",
    "    data.train_d = np.array([1 - y_prob[y_true] for y_prob, y_true in zip(pred_proba, data.train_y)])\n",
    "    print('train instances difficulty: mean=%f, std=%f' % (np.mean(data.train_d), np.std(data.train_d)))\n",
    "    \n",
    "    all_difficulties = np.hstack([data.train_d, data.test_d])\n",
    "    data.d_mean = np.mean(all_difficulties)\n",
    "    data.d_std = np.var(all_difficulties)\n",
    "    nbins = 100\n",
    "    data.hist, data.bin_edges = np.histogram(all_difficulties, bins=nbins)\n",
    "    plt.hist(all_difficulties, bins=nbins)\n",
    "    plt.show()\n",
    "    print('difficulty mean: %f, difficulty variance: %f' % (data.d_mean, data.d_std))\n",
    "    print(data.train_x[0])\n",
    "    print(data.train_x.shape[0])\n",
    "    return data\n",
    "\n",
    "data = read_imdb_text(IMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.py\n",
    "backdoor_adjustment = lambda x,y,z,t,u: backdoor_adjustment_var_C(x,y,z,1.,t,u)\n",
    "backdoor_adjustment_Z10 = lambda x,y,z,t,u: backdoor_adjustment_var_C(x,y,z,10,t,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confounding_trials(models, data, ntrials, rand):  \n",
    "    \"\"\" Do several random trials in which we sample data with a confounding variable. \n",
    "    Plot the average accuracies as confounding bias increases.\n",
    "    \"\"\"\n",
    "    test_biases = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "    train_biases = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "    \n",
    "#     test_biases = [.1,.5,.9]\n",
    "#     train_biases = [.1,.5,.9]\n",
    "    \n",
    "    corr_diffs = []\n",
    "    accuracies = defaultdict(lambda: defaultdict(lambda: []))\n",
    "    idx_horror = np.where(data.feature_names == 'horror')\n",
    "    \n",
    "    for train_bias in train_biases:\n",
    "        for test_bias in test_biases:\n",
    "            for ti in range(ntrials):\n",
    "                # Sample training and testing indices.\n",
    "                test_idx = make_confounding_data(X=data.test_x, y=data.test_y, c=data.test_c,\n",
    "                                                pos_prob=.5, bias=test_bias, size=1400, rand=rand)  \n",
    "                test_corr = pearsonr(data.test_y[test_idx], data.test_c[test_idx])[0]\n",
    "                train_idx = make_confounding_data(X=data.train_x, y=data.train_y, c=data.train_c,\n",
    "                                                  pos_prob=.5, bias=train_bias, size=1500, rand=rand)   \n",
    "                train_corr = pearsonr(data.train_y[train_idx], data.train_c[train_idx])[0]\n",
    "                corr_diff = round(train_corr - test_corr, 1)\n",
    "                if ti == 0:\n",
    "                    corr_diffs.append(corr_diff)\n",
    "                    print('train_bias=', train_bias, 'train_corr=', train_corr,\n",
    "                          'test_bias=', test_bias, 'test_corr=', test_corr,\n",
    "                          'corr_diff=', corr_diff)\n",
    "                    \n",
    "                # Train and test each model.\n",
    "                for name, model in models:\n",
    "                    clf = model(data.train_x[train_idx], data.train_y[train_idx],\n",
    "                                data.train_c[train_idx], rand, data.feature_names)\n",
    "                    y_pred = clf.predict(data.test_x[test_idx])\n",
    "                    y_true = data.test_y[test_idx]\n",
    "                    for y in range(3):\n",
    "                        for c in range(3):\n",
    "                            k = 3*y+c\n",
    "                            cond = lambda x: (c == 2 or data.test_c[x] == c) and (y == 2 or data.test_y[x] == y)\n",
    "                            yc_test_idx = [i for i, j in enumerate(test_idx) if cond(j)]\n",
    "                            accuracies[k][name].append({'test_bias': test_bias, 'train_bias': train_bias,\n",
    "                                                        'corr_diff': corr_diff,\n",
    "                                                        'acc': accuracy_score(y_true[yc_test_idx],\n",
    "                                                                              y_pred[yc_test_idx])})\n",
    "                        \n",
    "    return accuracies, corr_diffs, test_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confound_expt(data, ntrials=3, models=[('feature_select', feature_select),('logreg', lr),              \n",
    "                                             ('matching', matching),('backdoor_adjustment', backdoor_adjustment)],\n",
    "                    confounding_function=do_confounding_trials):                                              \n",
    "    rand = np.random.RandomState(1234567)                                                                     \n",
    "    clf = lr(data.train_x, data.train_y, data.train_c, rand, data.feature_names)                              \n",
    "    print('og testing accuracy=', accuracy_score(data.test_y, clf.predict(data.test_x)))                      \n",
    "    print('----------------\\nExperiments using genre as a confounder:')                                       \n",
    "    return confounding_function(models, data, ntrials, rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('overall training correlation between genre and sentiment:', pearsonr(data.train_y, data.train_c))\n",
    "print('overall testing correlation between genre and sentiment:', pearsonr(data.test_y, data.test_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounding experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results for every possible pair y/c with original function make confounding data\n",
    "models = [('LR', lr), ('M', matching), ('BAZ10', backdoor_adjustment_Z10),\n",
    "          ('SO', sumout), ('LRS', lr_subsampling), ('BA', backdoor_adjustment)]\n",
    "accuracies, corr_diffs, test_biases = do_confound_expt(data, ntrials=5, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bias_axis = (test_biases, 'test_bias', 'Test Bias')\n",
    "corr_diff_axis = (corr_diffs, 'corr_diff', 'correlation difference (train-test)')\n",
    "\n",
    "plot_all_accuracies(accuracies, test_bias_axis, title='Average accuracy/Test bias', xlim=[0,1])\n",
    "plot_all_accuracies(accuracies, corr_diff_axis, title='Accuracy/Correlation difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for y in range(3):\n",
    "    for c in range(3):\n",
    "        plot_accuracy(accuracies, test_bias_axis, y=y, c=c, xlim=[0,1])\n",
    "        plot_accuracy(accuracies, corr_diff_axis, y=y, c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tr_bias in np.arange(0.1, 1., 0.1):\n",
    "    ylabel=\"Accuracy for train bias=%.1f\" % tr_bias\n",
    "    export_plot_accuracy('test', accuracies, test_bias_axis, 2, 2, title='', xlabel='Test bias', train_bias=tr_bias,\n",
    "                         ylabel=ylabel, xlim=[0.,1.], set_xticks=np.arange(0.1,1.,.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [1, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Export IMDb plots\n",
    "fig = export_plot_accuracy('../paper/figures/imdb_accuracy_corr_diff.pdf',\n",
    "                           accuracies, corr_diff_axis, 2, 2, title='',\n",
    "                           xlabel='Correlation difference (train-test)',\n",
    "                           ylabel='Accuracy',\n",
    "                           mask=mask)\n",
    "\n",
    "fig = export_plot_accuracy('../paper/figures/imdb_accuracy_test_bias.pdf',\n",
    "                           accuracies, test_bias_axis, 2, 2, title='',\n",
    "                           xlabel='Test bias',\n",
    "                           ylabel='Accuracy', xlim=[0.,1.], set_xticks=np.arange(0.1,1.,.1),\n",
    "                           mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpson's paradox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run simpson_paradox.py\n",
    "%run models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = [('LR', lr), ('BA', backdoor_adjustment), ('BAZ10', backdoor_adjustment_Z10)]\n",
    "rand = np.random.RandomState(111191)\n",
    "biases, spa_count_bias_results = simpson_paradox_count_bias(data, methods, 1400, rand=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markers = {'LR': 'rx-', 'LRS': 'cD-', 'BA': 'bs-','BAZ10': 'gv-','SO': 'y*-', 'M': 'm^-'}\n",
    "plot_spa_results(biases, spa_count_bias_results, markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study effect of C value on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.py\n",
    "%run ba_c_study.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_range = np.logspace(-3, 4, 15)\n",
    "methods = [('BA', backdoor_adjustment_var_C)]\n",
    "filter_corr_diff = lambda x: np.abs(x) > .6\n",
    "accuracies_c, coefs_c = do_c_study(c_range, filter_corr_diff, data, 10,\n",
    "                                   np.random.RandomState(111191), 1400, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_c_study(c_range, accuracies_c, coefs_c, tofile='test.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run most_changing_coef.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = dict(data=data,\n",
    "              n=30,\n",
    "              models=[(lr, 'LR','rx'), (backdoor_adjustment, 'BA','bs')],\n",
    "              biases=[.1,.5,.9],\n",
    "              size=1350,\n",
    "              transformation=most_changing_coef,\n",
    "              class_labels=['neg. sentiment', 'pos. sentiment'])\n",
    "changing_coef_plot(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = dict(data=data,\n",
    "              n=30,\n",
    "              models=[(lr, 'LR','rx'), (backdoor_adjustment, 'BA','bs')],\n",
    "              biases=[.1,.5,.9],\n",
    "              size=1350,\n",
    "              transformation=most_changing_sign_coef,\n",
    "              class_labels=['neg. sentiment', 'pos. sentiment'])\n",
    "changing_coef_plot(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Top terms table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run top_terms_table.py\n",
    "%run models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_top_coef_table(data, lr, 10, 1400, 30, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_top_coef_table(data, backdoor_adjustment, 10, 1400, 30, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_top_coef_table(data, backdoor_adjustment_Z10, 10, 1400, 30, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
