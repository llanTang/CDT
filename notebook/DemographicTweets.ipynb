{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Dataset\n",
    "\n",
    "In this notebook, we apply the back-door adjustment method to a dataset extracted from Twitter. Each user has been annotated with its location (NY or LA) and its gender (Male or Female).\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Load data from disk][1]\n",
    "  1. [Download data from Dropbox][2]\n",
    "  2. [Load data (functions)][3]\n",
    "  3. [Load data (functions calls)][4]\n",
    "    1. [Use gender as a confounder][5]\n",
    "    2. [Use location as a confounder][6]\n",
    "2. [Experiments][7]\n",
    "  1. [Load models][8]\n",
    "  2. [Experiment helper functions][9]\n",
    "  3. [Predict location with gender as a confounder][10]\n",
    "    1. [Accuracy experiment][11]\n",
    "    2. [Export figures][12]\n",
    "    3. [Simpson's paradox][13]\n",
    "    4. [Most changing features][14]\n",
    "    5. [Study effect of C on accuracy][15]\n",
    "    6. [Top terms table][16]\n",
    "  4. [Predict gender with location as a confounder][17]\n",
    "    1. [Accuracy experiment][18]\n",
    "    2. [Most changing features][19]\n",
    "    3. [Top terms table][20]\n",
    "[1]: #Load-data-from-disk\n",
    "[2]: #Download-data-from-Dropbox\n",
    "[3]: #Load-data-(functions)\n",
    "[4]: #Load-data-(functions-calls)\n",
    "[5]: #Use-gender-as-a-confounder\n",
    "[6]: #Use-location-as-a-confounder\n",
    "[7]: #Experiments\n",
    "[8]: #Load-models\n",
    "[9]: #Experiment-helper-functions\n",
    "[10]: #Predict-location-with-gender-as-a-confounder\n",
    "[11]: #Accuracy-experiment\n",
    "[12]: #Export-figures\n",
    "[13]: #Simpson's-paradox\n",
    "[14]: #Most-changing-features\n",
    "[15]: #Study-effect-of-C-on-accuracy\n",
    "[16]: #Top-terms-table\n",
    "[17]: #Predict-gender-with-location-as-a-confounder\n",
    "[18]: #Accuracy-experiment\n",
    "[19]: #Most-changing-features\n",
    "[20]: #Top-terms-table                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from disk\n",
    "\n",
    "### Download data from Dropbox\n",
    "The process of creating the dataset from 6000 users takes ~2 hours. Therefore, the results have been pickled and can be reloaded in ordered to get the dataset. Our data is [stored on Dropbox](https://www.dropbox.com/sh/pcg731664f8h4fy/AAD9GSey11NGJjgIgXsm5Mw9a/twitter.tgz?dl=1) and its access is protected by a password. If you are interested in using the data for research purposes, please email one of the author to obtain the password. Once you have downloaded and unpacked the data, set the following `DATAPATH` variable to the path where the data is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to the data\n",
    "DATAPATH = '/Users/ustctll/Desktop/dataset'\n",
    "TWITTER_PATH = os.path.join(DATAPATH, 'twitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    pass\n",
    "\n",
    "def load_dataset(users_pkl, term_doc_matrix_pkl, vectorizer_pkl=None, confounder_key='gender',\n",
    "                 train_ratio=.5, rand=np.random.RandomState(111191)):\n",
    "    data = Data()\n",
    "    if vectorizer_pkl is not None:\n",
    "        print(\"Loading feature names through vectorizer...\")\n",
    "        with open(vectorizer_pkl, 'rb') as f:\n",
    "            vec = pickle.load(f)\n",
    "        data.feature_names = np.array(vec.get_feature_names())[:20]\n",
    "    print(\"Loading users pickle...\")\n",
    "    with open(users_pkl, 'rb') as f:\n",
    "        all_users = pickle.load(f)\n",
    "    print(\"Load term document matrix pickle...\")\n",
    "    with open(term_doc_matrix_pkl, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    print(\"Getting label and confounder for every user...\")\n",
    "    Y = []\n",
    "    C = []\n",
    "    label_key = 'location' if confounder_key == 'gender' else 'gender'\n",
    "    for city_users in all_users:\n",
    "        for u in city_users:\n",
    "            C.append(u[confounder_key])\n",
    "            Y.append(u[label_key])\n",
    "    print(\"Done\")\n",
    "    print(\"%d users, %d features\" % X.shape)\n",
    "    C_set = set(C)\n",
    "    Y_set = set(Y)\n",
    "    for dc in C_set:\n",
    "        for dy in Y_set:\n",
    "            print(\"\\tc = %s and y = %s: %d users\" % (dc, dy, len([i for i in range(len(Y)) if Y[i]==dy and C[i]==dc])))\n",
    "            \n",
    "    le_C = preprocessing.LabelEncoder()\n",
    "    le_Y = preprocessing.LabelEncoder()\n",
    "    C_int = le_C.fit_transform(C)\n",
    "    Y_int = le_Y.fit_transform(Y)\n",
    "    print(le_C.classes_)\n",
    "    print(le_Y.classes_)\n",
    "    \n",
    "    indices = list(range(X.shape[0]))\n",
    "    rand.shuffle(indices)\n",
    "    train_size = int(train_ratio * X.shape[0])\n",
    "    train_idx = indices[:train_size]\n",
    "    test_idx = indices[train_size:]\n",
    "    data.train_x = X[train_idx,:100]\n",
    "    data.test_x = X[test_idx,:100]\n",
    "    data.train_c = C_int[train_idx]\n",
    "    data.test_c = C_int[test_idx]\n",
    "    data.train_y = Y_int[train_idx]\n",
    "    data.test_y = Y_int[test_idx]\n",
    "    print(data.train_x)\n",
    "    print(data.train_y)\n",
    "    print('lengths: x_train %d y_train %d c_train %d' % (data.train_x.shape[0], data.train_y.shape[0], data.train_c.shape[0]))\n",
    "    print('train y distr', Counter(data.train_y), 'c distr', Counter(data.train_c))\n",
    "    print('train y and c distr', Counter(['y=%d,c=%d' % (y,c) for (y,c) in zip(data.train_y,data.train_c)]))\n",
    "    \n",
    "    print('lengths: x_test %d y_test %d c_test %d' % (data.test_x.shape[0], data.test_y.shape[0], data.test_c.shape[0]))\n",
    "    print('test y distr', Counter(data.test_y), 'c distr', Counter(data.test_c))\n",
    "    print('test y and c distr', Counter(['y=%d,c=%d' % (y,c) for (y,c) in zip(data.test_y,data.test_c)]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (functions calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use gender as a confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature names through vectorizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator CountVectorizer from version pre-0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading users pickle...\n",
      "Load term document matrix pickle...\n",
      "Getting label and confounder for every user...\n",
      "Done\n",
      "6000 users, 21981 features\n",
      "\tc = f and y = la: 1500 users\n",
      "\tc = f and y = ny: 1500 users\n",
      "\tc = m and y = la: 1500 users\n",
      "\tc = m and y = ny: 1500 users\n",
      "['f' 'm']\n",
      "['la' 'ny']\n",
      "  (0, 15)\t1\n",
      "  (0, 88)\t1\n",
      "  (1, 65)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 43)\t1\n",
      "  (1, 26)\t1\n",
      "  (1, 87)\t1\n",
      "  (1, 59)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 75)\t1\n",
      "  (1, 44)\t1\n",
      "  (1, 16)\t1\n",
      "  (2, 86)\t1\n",
      "  (2, 54)\t1\n",
      "  (2, 96)\t1\n",
      "  (2, 91)\t1\n",
      "  (2, 47)\t1\n",
      "  (2, 70)\t1\n",
      "  (2, 99)\t1\n",
      "  (2, 33)\t1\n",
      "  (2, 65)\t1\n",
      "  (2, 56)\t1\n",
      "  (2, 78)\t1\n",
      "  (2, 14)\t1\n",
      "  :\t:\n",
      "  (2997, 6)\t1\n",
      "  (2997, 26)\t1\n",
      "  (2997, 23)\t1\n",
      "  (2997, 87)\t1\n",
      "  (2997, 60)\t1\n",
      "  (2997, 61)\t1\n",
      "  (2997, 48)\t1\n",
      "  (2997, 41)\t1\n",
      "  (2997, 11)\t1\n",
      "  (2997, 69)\t1\n",
      "  (2997, 24)\t1\n",
      "  (2997, 59)\t1\n",
      "  (2997, 1)\t1\n",
      "  (2997, 88)\t1\n",
      "  (2997, 75)\t1\n",
      "  (2997, 42)\t1\n",
      "  (2997, 0)\t1\n",
      "  (2997, 17)\t1\n",
      "  (2997, 44)\t1\n",
      "  (2997, 16)\t1\n",
      "  (2998, 12)\t1\n",
      "  (2998, 88)\t1\n",
      "  (2998, 0)\t1\n",
      "  (2998, 44)\t1\n",
      "  (2999, 16)\t1\n",
      "[1 1 1 ... 1 1 0]\n",
      "lengths: x_train 3000 y_train 3000 c_train 3000\n",
      "train y distr Counter({0: 1527, 1: 1473}) c distr Counter({1: 1511, 0: 1489})\n",
      "train y and c distr Counter({'y=0,c=1': 772, 'y=0,c=0': 755, 'y=1,c=1': 739, 'y=1,c=0': 734})\n",
      "lengths: x_test 3000 y_test 3000 c_test 3000\n",
      "test y distr Counter({1: 1527, 0: 1473}) c distr Counter({0: 1511, 1: 1489})\n",
      "test y and c distr Counter({'y=1,c=0': 766, 'y=1,c=1': 761, 'y=0,c=0': 745, 'y=0,c=1': 728})\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(users_pkl=os.path.join(TWITTER_PATH, \"users_array.pkl\"),\n",
    "                    term_doc_matrix_pkl=os.path.join(TWITTER_PATH, \"term_doc_matrix.pkl\"),\n",
    "                    vectorizer_pkl=os.path.join(TWITTER_PATH, \"vectorizer.pkl\"),\n",
    "                    confounder_key='gender',\n",
    "                    train_ratio=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use location as a confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature names through vectorizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator CountVectorizer from version pre-0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading users pickle...\n",
      "Load term document matrix pickle...\n",
      "Getting label and confounder for every user...\n",
      "Done\n",
      "6000 users, 21981 features\n",
      "\tc = la and y = f: 1500 users\n",
      "\tc = la and y = m: 1500 users\n",
      "\tc = ny and y = f: 1500 users\n",
      "\tc = ny and y = m: 1500 users\n",
      "['la' 'ny']\n",
      "['f' 'm']\n",
      "  (0, 55)\t1\n",
      "  (0, 66)\t1\n",
      "  (0, 86)\t1\n",
      "  (0, 84)\t1\n",
      "  (0, 83)\t1\n",
      "  (0, 96)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 78)\t1\n",
      "  (0, 81)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 82)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 87)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 69)\t1\n",
      "  (0, 59)\t1\n",
      "  :\t:\n",
      "  (2997, 16)\t1\n",
      "  (2998, 98)\t1\n",
      "  (2998, 68)\t1\n",
      "  (2998, 96)\t1\n",
      "  (2998, 14)\t1\n",
      "  (2998, 10)\t1\n",
      "  (2998, 5)\t1\n",
      "  (2998, 6)\t1\n",
      "  (2998, 60)\t1\n",
      "  (2998, 73)\t1\n",
      "  (2998, 11)\t1\n",
      "  (2998, 59)\t1\n",
      "  (2998, 1)\t1\n",
      "  (2998, 58)\t1\n",
      "  (2998, 88)\t1\n",
      "  (2998, 75)\t1\n",
      "  (2998, 74)\t1\n",
      "  (2998, 44)\t1\n",
      "  (2998, 16)\t1\n",
      "  (2999, 31)\t1\n",
      "  (2999, 56)\t1\n",
      "  (2999, 45)\t1\n",
      "  (2999, 1)\t1\n",
      "  (2999, 44)\t1\n",
      "  (2999, 16)\t1\n",
      "[0 1 0 ... 0 0 0]\n",
      "lengths: x_train 3000 y_train 3000 c_train 3000\n",
      "train y distr Counter({0: 1503, 1: 1497}) c distr Counter({0: 1501, 1: 1499})\n",
      "train y and c distr Counter({'y=0,c=1': 762, 'y=1,c=0': 760, 'y=0,c=0': 741, 'y=1,c=1': 737})\n",
      "lengths: x_test 3000 y_test 3000 c_test 3000\n",
      "test y distr Counter({1: 1503, 0: 1497}) c distr Counter({1: 1501, 0: 1499})\n",
      "test y and c distr Counter({'y=1,c=1': 763, 'y=0,c=0': 759, 'y=1,c=0': 740, 'y=0,c=1': 738})\n"
     ]
    }
   ],
   "source": [
    "data2 = load_dataset(users_pkl=os.path.join(TWITTER_PATH, \"users_array.pkl\"),\n",
    "                    term_doc_matrix_pkl=os.path.join(TWITTER_PATH, \"term_doc_matrix.pkl\"),\n",
    "                    vectorizer_pkl=os.path.join(TWITTER_PATH, \"vectorizer.pkl\"),\n",
    "                    confounder_key='location',\n",
    "                    train_ratio=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.py\n",
    "%run injecting_bias.py\n",
    "%run confound_plot.py\n",
    "%run most_changing_coef.py\n",
    "%run ba_c_study.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor_adjustment = lambda x,y,z,t,u: backdoor_adjustment_var_C(x,y,z,1.,t,u,)\n",
    "backdoor_adjustment_Z10 = lambda x,y,z,t,u: backdoor_adjustment_var_C(x,y,z,10,t,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confounding_trials(models, data, ntrials, rand):  \n",
    "    \"\"\" Do several random trials in which we sample data with a confounding variable. \n",
    "    Plot the average accuracies as confounding bias increases.\n",
    "    \"\"\"\n",
    "    #test_biases = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "    #train_biases = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "    test_biases = [.5]\n",
    "    train_biases = [.5]\n",
    "#     test_biases = [.1, .5, .9]\n",
    "#     train_biases = [.1, .5, .9]\n",
    "    corr_diffs = []\n",
    "    accuracies = defaultdict(lambda: defaultdict(lambda: []))\n",
    "    \n",
    "    for train_bias in train_biases:\n",
    "        for test_bias in test_biases:\n",
    "            for ti in range(ntrials):\n",
    "                # Sample training and testing indices.\n",
    "                test_idx = make_confounding_data(X=data.test_x, y=data.test_y, c=data.test_c,\n",
    "                                                pos_prob=.5, bias=test_bias, size=800, rand=rand)  \n",
    "                test_corr = pearsonr(data.test_y[test_idx], data.test_c[test_idx])[0]\n",
    "                train_idx = make_confounding_data(X=data.train_x, y=data.train_y, c=data.train_c,\n",
    "                                                  pos_prob=.5, bias=train_bias, size=800, rand=rand)   \n",
    "                train_corr = pearsonr(data.train_y[train_idx], data.train_c[train_idx])[0]\n",
    "                corr_diff = round(train_corr - test_corr, 1)\n",
    "                if ti == 0:\n",
    "                    corr_diffs.append(corr_diff)\n",
    "                    print('train_bias=', train_bias, 'train_corr=', train_corr,\n",
    "                          'test_bias=', test_bias, 'test_corr=', test_corr,\n",
    "                          'corr_diff=', corr_diff)\n",
    "                    \n",
    "                # Train and test each model.\n",
    "                for name, model in models:\n",
    "                    clf = model(data.train_x[train_idx], data.train_y[train_idx],\n",
    "                                data.train_c[train_idx], rand, data.feature_names)\n",
    "                    y_pred = clf.predict(data.test_x[test_idx])\n",
    "                    y_true = data.test_y[test_idx]\n",
    "                    for y in range(3):\n",
    "                        for c in range(3):\n",
    "                            k = 3*y+c\n",
    "                            cond = lambda x: (c == 2 or data.test_c[x] == c) and (y == 2 or data.test_y[x] == y)\n",
    "                            yc_test_idx = [i for i, j in enumerate(test_idx) if cond(j)]\n",
    "                            accuracies[k][name].append({'test_bias': test_bias, 'train_bias': train_bias,\n",
    "                                                        'corr_diff': corr_diff,\n",
    "                                                        'acc': accuracy_score(y_true[yc_test_idx],\n",
    "                                                                              y_pred[yc_test_idx])})\n",
    "                            print('name',name,'acc',accuracy_score(y_true[yc_test_idx], y_pred[yc_test_idx]))\n",
    "                        \n",
    "    return accuracies, corr_diffs, test_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_confound_expt(data, ntrials=3, models=[('feature_select', feature_select),('logreg', lr),              \n",
    "                                             ('matching', matching),('backdoor_adjustment', backdoor_adjustment)],\n",
    "                    confounding_function=do_confounding_trials):                                              \n",
    "    rand = np.random.RandomState(1234567)                                                                     \n",
    "    clf = lr(data.train_x, data.train_y, data.train_c, rand, data.feature_names)                              \n",
    "    print('og testing accuracy=', accuracy_score(data.test_y, clf.predict(data.test_x)))                      \n",
    "    print('----------------\\nExperiments using genre as a confounder:')                                       \n",
    "    return confounding_function(models, data, ntrials, rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict location with gender as a confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og testing accuracy= 0.518\n",
      "----------------\n",
      "Experiments using genre as a confounder:\n",
      "train_bias= 0.5 train_corr= 0.0 test_bias= 0.5 test_corr= 0.0 corr_diff= 0.0\n",
      "name LR acc 0.5544554455445545\n",
      "name LR acc 0.5656565656565656\n",
      "name LR acc 0.56\n",
      "name LR acc 0.5\n",
      "name LR acc 0.4696969696969697\n",
      "name LR acc 0.485\n",
      "name LR acc 0.5272277227722773\n",
      "name LR acc 0.5176767676767676\n",
      "name LR acc 0.5225\n",
      "name M acc 0.7376237623762376\n",
      "name M acc 0.7373737373737373\n",
      "name M acc 0.7375\n",
      "name M acc 0.3613861386138614\n",
      "name M acc 0.3282828282828283\n",
      "name M acc 0.345\n",
      "name M acc 0.5495049504950495\n",
      "name M acc 0.5328282828282829\n",
      "name M acc 0.54125\n",
      "name BA acc 0.5643564356435643\n",
      "name BA acc 0.5656565656565656\n",
      "name BA acc 0.565\n",
      "name BA acc 0.504950495049505\n",
      "name BA acc 0.47474747474747475\n",
      "name BA acc 0.49\n",
      "name BA acc 0.5346534653465347\n",
      "name BA acc 0.5202020202020202\n",
      "name BA acc 0.5275\n",
      "name SO acc 0.5693069306930693\n",
      "name SO acc 0.5555555555555556\n",
      "name SO acc 0.5625\n",
      "name SO acc 0.5198019801980198\n",
      "name SO acc 0.494949494949495\n",
      "name SO acc 0.5075\n",
      "name SO acc 0.5445544554455446\n",
      "name SO acc 0.5252525252525253\n",
      "name SO acc 0.535\n",
      "name LRS acc 0.5643564356435643\n",
      "name LRS acc 0.5707070707070707\n",
      "name LRS acc 0.5675\n",
      "name LRS acc 0.49504950495049505\n",
      "name LRS acc 0.4797979797979798\n",
      "name LRS acc 0.4875\n",
      "name LRS acc 0.5297029702970297\n",
      "name LRS acc 0.5252525252525253\n",
      "name LRS acc 0.5275\n",
      "name BAZ10 acc 0.5643564356435643\n",
      "name BAZ10 acc 0.5656565656565656\n",
      "name BAZ10 acc 0.565\n",
      "name BAZ10 acc 0.504950495049505\n",
      "name BAZ10 acc 0.47474747474747475\n",
      "name BAZ10 acc 0.49\n",
      "name BAZ10 acc 0.5346534653465347\n",
      "name BAZ10 acc 0.5202020202020202\n",
      "name BAZ10 acc 0.5275\n",
      "name CDT acc 0.8118811881188119\n",
      "name CDT acc 0.8787878787878788\n",
      "name CDT acc 0.845\n",
      "name CDT acc 0.13861386138613863\n",
      "name CDT acc 0.18181818181818182\n",
      "name CDT acc 0.16\n",
      "name CDT acc 0.4752475247524752\n",
      "name CDT acc 0.5303030303030303\n",
      "name CDT acc 0.5025\n"
     ]
    }
   ],
   "source": [
    "models = [('LR', lr), ('M', matching), ('BA', backdoor_adjustment), ('SO', sumout), ('LRS', lr_subsampling),\n",
    "          ('BAZ10', backdoor_adjustment_Z10),('CDT',cdtAlg)]\n",
    "#models = [('CDT',cdtAlg)]\n",
    "accuracies, corr_diffs, test_biases = do_confound_expt(data, ntrials=1, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-76f475943786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mto_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'logistic regression'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_all_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bias_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Average accuracy/Test bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, keys=to_plot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplot_all_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_diff_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy/Correlation difference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, keys=to_plot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyterDir/aaai-2016-robust-master/notebook/confound_plot.py\u001b[0m in \u001b[0;36mplot_all_accuracies\u001b[0;34m(all_accuracies, x_axis_tuple, title, xlim, keys, train_bias)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0macc_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_bias_axis = (test_biases, 'test_bias', 'Test Bias')\n",
    "corr_diff_axis = (corr_diffs, 'corr_diff', 'correlation difference (train-test)')\n",
    "\n",
    "to_plot = ['logistic regression']\n",
    "plot_all_accuracies(accuracies, test_bias_axis, title='Average accuracy/Test bias', xlim=[0,1])#, keys=to_plot)\n",
    "plot_all_accuracies(accuracies, corr_diff_axis, title='Accuracy/Correlation difference')#, keys=to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(3):\n",
    "    for c in range(3):\n",
    "        plot_accuracy(accuracies, test_bias_axis, y=y, c=c, xlim=[0,1])\n",
    "        plot_accuracy(accuracies, corr_diff_axis, y=y, c=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tr_bias in np.arange(0.1, 1., 0.1):\n",
    "    ylabel=\"Accuracy for train bias=%.1f\" % tr_bias\n",
    "    export_plot_accuracy('test', accuracies, test_bias_axis, 2, 2, title='', xlabel='Test bias', train_bias=tr_bias,\n",
    "                         ylabel=ylabel, xlim=[0.,1.], set_xticks=np.arange(0.1,1.,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = ['BA', 'BAZ10', 'LR', 'M', 'LRS']\n",
    "\n",
    "# Export IMDb plots\n",
    "fig = export_plot_accuracy('../paper/figures/twitter_accuracy_corr_diff.pdf',\n",
    "                           accuracies, corr_diff_axis, 2, 2, title='',\n",
    "                           xlabel='Correlation difference (train-test)', ncol=3,\n",
    "                           ylabel='Accuracy')\n",
    "\n",
    "fig = export_plot_accuracy('../paper/figures/twitter_accuracy_test_bias.pdf',\n",
    "                           accuracies, test_bias_axis, 2, 2, title='', ncol=3,\n",
    "                           xlabel='Test bias',\n",
    "                           ylabel='Accuracy averaged over the training biases', xlim=[0.,1.], set_xticks=np.arange(0.1,1.,.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpson's paradox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run simpson_paradox.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [('BAZ10', backdoor_adjustment_Z10), ('LR', lr), ('LRS', lr_subsampling), ('BA', backdoor_adjustment)]\n",
    "rand = np.random.RandomState(111191)\n",
    "biases, spa_count_bias_results = simpson_paradox_count_bias(data, methods, 800, rand=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {\n",
    "    'BAZ10': 'gv-',\n",
    "    'LR': 'rx-',\n",
    "    'BA': 'bs-',\n",
    "    'LRS': 'cD-'\n",
    "}\n",
    "plot_spa_results(biases, spa_count_bias_results, markers, tofile=\"../paper/figures/simpson_paradox_expt.pdf\", n_fts=21981.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most changing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run most_changing_coef.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = dict(data=data,\n",
    "              n=30,\n",
    "              models=[(backdoor_adjustment, 'BA', 'bs'), (backdoor_adjustment_Z10, 'BAZ10', 'gv')],\n",
    "              biases=[.1,.5,.9],\n",
    "              size=800,\n",
    "              transformation=most_changing_coef,\n",
    "              class_labels=['Los Angeles', 'New York'],\n",
    "              feature_names=np.hstack([data.feature_names, ['c=0', 'c=1']]))\n",
    "changing_coef_plot(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run most_changing_coef.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x2, pval = chi2(data.train_x, data.train_c)\n",
    "top_ft_idx = np.argsort(x2)[::-1][:10][::-1]\n",
    "params = dict(data=data,\n",
    "              models=[(lr, 'LR', 'rx'), (backdoor_adjustment, 'BA', 'bs'), (backdoor_adjustment_Z10, 'BAZ10', 'gv')],\n",
    "              biases=[.9],\n",
    "              size=800,\n",
    "              trials=2,\n",
    "              class_labels=['Los Angeles', 'New York'],\n",
    "              indices=top_ft_idx)\n",
    "changing_coef_plot_given_idx(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x2, pval = chi2(data.train_x, data.train_y)\n",
    "top_ft_idx = np.argsort(x2)[::-1][:10][::-1]\n",
    "params = dict(data=data,\n",
    "              models=[(lr, 'LR', 'rx'), (backdoor_adjustment, 'BA', 'bs'), (backdoor_adjustment_Z10, 'BAZ10', 'gv')],\n",
    "              biases=[.9],\n",
    "              size=800,\n",
    "              trials=2,\n",
    "              class_labels=['Los Angeles', 'New York'],\n",
    "              indices=top_ft_idx)\n",
    "changing_coef_plot_given_idx(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study effect of C on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range = np.logspace(-3, 4, 15)\n",
    "methods = [('BA', backdoor_adjustment_var_C)]\n",
    "filter_corr_diff = lambda x: np.abs(x) > 1.2\n",
    "accuracies_c, coefs_c = do_c_study(c_range, filter_corr_diff, data, 5,\n",
    "                                   np.random.RandomState(111191), 800, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_c_study(c_range, accuracies_c, coefs_c, tofile='../paper/figures/ba_c_study.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top terms table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run top_terms_table.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_top_coef_table(data, lr, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_top_coef_table(data, backdoor_adjustment, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_top_coef_table(data, backdoor_adjustment_Z10, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict gender with location as a confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [('LR', lr), ('M', matching), ('BA', backdoor_adjustment), ('SO', sumout), ('LRS', lr_subsampling),\n",
    "          ('BAZ10', backdoor_adjustment_Z10)]\n",
    "accuracies2, corr_diffs2, test_biases2 = do_confound_expt(data2, ntrials=5, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_bias_axis2 = (test_biases2, 'test_bias', 'Test Bias')\n",
    "corr_diff_axis2 = (corr_diffs2, 'corr_diff', 'correlation difference (train-test)')\n",
    "\n",
    "plot_all_accuracies(accuracies2, test_bias_axis2, title='Average accuracy/Test bias', xlim=[0,1])#, keys=to_plot)\n",
    "plot_all_accuracies(accuracies2, corr_diff_axis2, title='Accuracy/Correlation difference')#, keys=to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for y in range(3):\n",
    "    for c in range(3):\n",
    "        plot_accuracy(accuracies2, test_bias_axis2, y=y, c=c, xlim=[0,1])#, keys=['lr subsampling', 'backdoor adjustment'])\n",
    "        plot_accuracy(accuracies2, corr_diff_axis2, y=y, c=c)#, keys=['lr subsampling', 'backdoor adjustment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most changing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run most_changing_coef.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = dict(data=data2,\n",
    "              n=30,\n",
    "              models=[(backdoor_adjustment, 'BA', 'bs'),(backdoor_adjustment_Z10, 'BAZ10', 'gv')],\n",
    "              biases=[.1,.5,.9],\n",
    "              size=800,\n",
    "              transformation=most_changing_coef,\n",
    "              class_labels=['Female', 'Male'],\n",
    "              feature_names=np.hstack([data.feature_names, ['c=0', 'c=1']]))\n",
    "changing_coef_plot(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = dict(data=data2,\n",
    "              n=60,\n",
    "              models=[(lr, 'LR', 'rx'), (backdoor_adjustment_Z10, 'BAZ10', 'gv')],\n",
    "              biases=[.1,.5,.9],\n",
    "              size=800,\n",
    "              transformation=most_changing_coef,\n",
    "              class_labels=['Female', 'Male'])\n",
    "changing_coef_plot(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top terms table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run top_terms_table.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_top_coef_table(data2, lr, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_top_coef_table(data2, backdoor_adjustment, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_top_coef_table(data2, backdoor_adjustment_Z10, 5, 800, 10, np.random.RandomState(111191), 1., data.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
